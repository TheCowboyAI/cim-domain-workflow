//! Algebraic Operations Implementation
//!
//! Implements the three core algebraic operations for the Workflow Event Algebra:
//! - Sequential Composition (⊕): Event ordering and chaining
//! - Parallel Composition (⊗): Concurrent event processing  
//! - Conditional Transformation (→): Context-dependent event routing

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::collections::{HashMap, HashSet};
use std::future::Future;
use std::pin::Pin;
use uuid::Uuid;

use super::event_algebra::{
    WorkflowEvent, EventType, RelationType, CausationChain,
    EventContext, EventPayload, SequentialIdentity, ParallelIdentity
};
use crate::primitives::WorkflowContext;

/// Result of algebraic operations on workflow events
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AlgebraicResult<T> {
    /// Operation result
    pub result: T,
    /// New events generated by the operation
    pub events: Vec<WorkflowEvent>,
    /// Updated causation relationships
    pub causations: Vec<(Uuid, Uuid, RelationType)>,
    /// Operation metadata
    pub metadata: OperationMetadata,
}

/// Metadata about algebraic operations
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OperationMetadata {
    /// Operation type
    pub operation_type: OperationType,
    /// Operation timestamp
    pub timestamp: chrono::DateTime<chrono::Utc>,
    /// Operation context
    pub context: HashMap<String, serde_json::Value>,
    /// Performance metrics
    pub metrics: OperationMetrics,
}

/// Types of algebraic operations
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum OperationType {
    SequentialComposition,
    ParallelComposition,
    ConditionalTransformation,
}

/// Operation performance metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OperationMetrics {
    /// Operation duration in microseconds
    pub duration_us: u64,
    /// Number of events processed
    pub events_processed: u32,
    /// Number of causation links created
    pub causations_created: u32,
}

/// Trait for sequential composition operations
#[async_trait]
pub trait SequentialComposition<T>: Send + Sync {
    /// Sequential composition operation (⊕)
    /// Combines two events in causal sequence
    async fn compose_sequential(
        &self,
        left: T,
        right: T,
        context: &WorkflowContext,
    ) -> Result<AlgebraicResult<T>, AlgebraicError>;

    /// Identity element for sequential composition
    fn sequential_identity() -> T;
}

/// Trait for parallel composition operations
#[async_trait]
pub trait ParallelComposition<T>: Send + Sync {
    /// Parallel composition operation (⊗)
    /// Combines two events for concurrent processing
    async fn compose_parallel(
        &self,
        left: T,
        right: T,
        context: &WorkflowContext,
    ) -> Result<AlgebraicResult<T>, AlgebraicError>;

    /// Identity element for parallel composition
    fn parallel_identity() -> T;
}

/// Trait for conditional transformation operations
#[async_trait]
pub trait ConditionalTransformation<T>: Send + Sync {
    /// Conditional transformation operation (→)
    /// Applies context-dependent transformations
    async fn transform_conditional(
        &self,
        event: T,
        condition: TransformationCondition,
        transformation: Box<dyn EventTransformation<T>>,
        context: &WorkflowContext,
    ) -> Result<AlgebraicResult<T>, AlgebraicError>;
}

/// Condition for conditional transformations
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TransformationCondition {
    /// Condition name
    pub name: String,
    /// Condition type
    pub condition_type: ConditionType,
    /// Condition parameters
    pub parameters: HashMap<String, serde_json::Value>,
}

/// Types of transformation conditions
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub enum ConditionType {
    /// Domain-based condition
    DomainCondition,
    /// Context-based condition
    ContextCondition,
    /// Event type condition
    EventTypeCondition,
    /// Custom condition
    CustomCondition,
}

/// Trait for event transformations
#[async_trait]
pub trait EventTransformation<T>: Send + Sync {
    /// Apply transformation to event
    async fn transform(
        &self,
        event: T,
        context: &WorkflowContext,
    ) -> Result<T, TransformationError>;
}

/// Concrete implementation of workflow event algebra operations
pub struct WorkflowEventAlgebra;

/// Event sequence for sequential composition
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EventSequence {
    /// Events in sequence
    pub events: Vec<WorkflowEvent>,
    /// Sequence metadata
    pub metadata: SequenceMetadata,
}

/// Event collection for parallel composition
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EventCollection {
    /// Events in collection
    pub events: Vec<WorkflowEvent>,
    /// Collection metadata
    pub metadata: CollectionMetadata,
}

/// Metadata for event sequences
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SequenceMetadata {
    /// Total sequence duration
    pub total_duration: Option<chrono::Duration>,
    /// Sequence dependencies
    pub dependencies: Vec<(Uuid, Uuid)>,
}

/// Metadata for event collections
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CollectionMetadata {
    /// Maximum parallel degree
    pub parallel_degree: u32,
    /// Synchronization points
    pub sync_points: Vec<Uuid>,
}

#[async_trait]
impl SequentialComposition<WorkflowEvent> for WorkflowEventAlgebra {
    async fn compose_sequential(
        &self,
        left: WorkflowEvent,
        right: WorkflowEvent,
        context: &WorkflowContext,
    ) -> Result<AlgebraicResult<WorkflowEvent>, AlgebraicError> {
        let start_time = std::time::Instant::now();

        // Validate sequential composition is valid
        if left.correlation_id != right.correlation_id {
            return Err(AlgebraicError::InvalidComposition(
                "Events must have same correlation ID for sequential composition".to_string()
            ));
        }

        // Create new causation relationship
        let mut new_causation_chain = right.causation_chain.clone();
        new_causation_chain.add_caused_by(right.id, left.id);

        // Create composed event (represents the sequence)
        let mut composed_event = right.clone();
        composed_event.causation_chain = new_causation_chain;
        composed_event.id = Uuid::new_v4(); // New ID for composition result
        composed_event.timestamp = chrono::Utc::now();

        // Add composition metadata to payload
        composed_event.payload.set_data(
            "composition_type".to_string(), 
            serde_json::json!("sequential")
        );
        composed_event.payload.set_data(
            "left_event_id".to_string(),
            serde_json::json!(left.id.to_string())
        );
        composed_event.payload.set_data(
            "right_event_id".to_string(),
            serde_json::json!(right.id.to_string())
        );

        let duration = start_time.elapsed();
        let metadata = OperationMetadata {
            operation_type: OperationType::SequentialComposition,
            timestamp: chrono::Utc::now(),
            context: context.global_context.variables.clone().into_iter()
                .map(|(k, v)| (k, v))
                .collect(),
            metrics: OperationMetrics {
                duration_us: duration.as_micros() as u64,
                events_processed: 2,
                causations_created: 1,
            },
        };

        let left_id = left.id;
        let right_id = right.id;

        Ok(AlgebraicResult {
            result: composed_event,
            events: vec![left, right],
            causations: vec![(right_id, left_id, RelationType::CausedBy)],
            metadata,
        })
    }

    fn sequential_identity() -> WorkflowEvent {
        WorkflowEvent::new(
            EventType::Extension(crate::algebra::event_algebra::ExtensionEventType::Custom("identity".to_string())),
            "system".to_string(),
            Uuid::nil(),
            EventPayload::empty(),
            EventContext::empty(),
        )
    }
}

#[async_trait]
impl ParallelComposition<WorkflowEvent> for WorkflowEventAlgebra {
    async fn compose_parallel(
        &self,
        left: WorkflowEvent,
        right: WorkflowEvent,
        context: &WorkflowContext,
    ) -> Result<AlgebraicResult<WorkflowEvent>, AlgebraicError> {
        let start_time = std::time::Instant::now();

        // Validate parallel composition is valid
        if left.correlation_id != right.correlation_id {
            return Err(AlgebraicError::InvalidComposition(
                "Events must have same correlation ID for parallel composition".to_string()
            ));
        }

        // Create parallel relationship
        let mut new_causation_chain = left.causation_chain.clone();
        new_causation_chain.add_parallel(left.id, right.id);

        // Create composed event representing parallel execution
        let composed_event = WorkflowEvent {
            id: Uuid::new_v4(),
            event_type: EventType::Extension(
                crate::algebra::event_algebra::ExtensionEventType::Custom("parallel_composition".to_string())
            ),
            domain: "system".to_string(),
            correlation_id: left.correlation_id,
            causation_chain: new_causation_chain,
            timestamp: chrono::Utc::now(),
            payload: {
                let mut payload = EventPayload::empty();
                payload.set_data("composition_type".to_string(), serde_json::json!("parallel"));
                payload.set_data("left_event_id".to_string(), serde_json::json!(left.id.to_string()));
                payload.set_data("right_event_id".to_string(), serde_json::json!(right.id.to_string()));
                payload
            },
            context: EventContext::empty(),
        };

        let duration = start_time.elapsed();
        let metadata = OperationMetadata {
            operation_type: OperationType::ParallelComposition,
            timestamp: chrono::Utc::now(),
            context: context.global_context.variables.clone().into_iter()
                .map(|(k, v)| (k, v))
                .collect(),
            metrics: OperationMetrics {
                duration_us: duration.as_micros() as u64,
                events_processed: 2,
                causations_created: 1,
            },
        };

        let left_id = left.id;
        let right_id = right.id;

        Ok(AlgebraicResult {
            result: composed_event,
            events: vec![left, right],
            causations: vec![(left_id, right_id, RelationType::ParallelTo)],
            metadata,
        })
    }

    fn parallel_identity() -> WorkflowEvent {
        WorkflowEvent::new(
            EventType::Extension(crate::algebra::event_algebra::ExtensionEventType::Custom("parallel_identity".to_string())),
            "system".to_string(),
            Uuid::nil(),
            EventPayload::empty(),
            EventContext::empty(),
        )
    }
}

#[async_trait]
impl ConditionalTransformation<WorkflowEvent> for WorkflowEventAlgebra {
    async fn transform_conditional(
        &self,
        event: WorkflowEvent,
        condition: TransformationCondition,
        transformation: Box<dyn EventTransformation<WorkflowEvent>>,
        context: &WorkflowContext,
    ) -> Result<AlgebraicResult<WorkflowEvent>, AlgebraicError> {
        let start_time = std::time::Instant::now();

        // Evaluate condition
        let should_transform = self.evaluate_condition(&event, &condition, context).await?;

        let result_event = if should_transform {
            // Apply transformation
            transformation.transform(event.clone(), context).await
                .map_err(|e| AlgebraicError::TransformationError(e))?
        } else {
            // Return original event
            event.clone()
        };

        let duration = start_time.elapsed();
        let metadata = OperationMetadata {
            operation_type: OperationType::ConditionalTransformation,
            timestamp: chrono::Utc::now(),
            context: {
                let mut ctx = context.global_context.variables.clone().into_iter()
                    .map(|(k, v)| (k, v))
                    .collect::<HashMap<_, _>>();
                ctx.insert("condition_applied".to_string(), serde_json::json!(should_transform));
                ctx.insert("condition_name".to_string(), serde_json::json!(condition.name));
                ctx
            },
            metrics: OperationMetrics {
                duration_us: duration.as_micros() as u64,
                events_processed: 1,
                causations_created: if should_transform { 1 } else { 0 },
            },
        };

        let causations = if should_transform && result_event.id != event.id {
            vec![(result_event.id, event.id, RelationType::CausedBy)]
        } else {
            vec![]
        };

        Ok(AlgebraicResult {
            result: result_event,
            events: vec![event],
            causations,
            metadata,
        })
    }
}

impl WorkflowEventAlgebra {
    /// Evaluate a transformation condition
    async fn evaluate_condition(
        &self,
        event: &WorkflowEvent,
        condition: &TransformationCondition,
        context: &WorkflowContext,
    ) -> Result<bool, AlgebraicError> {
        match condition.condition_type {
            ConditionType::DomainCondition => {
                let expected_domain = condition.parameters.get("domain")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| AlgebraicError::InvalidCondition(
                        "Domain condition requires 'domain' parameter".to_string()
                    ))?;
                Ok(event.domain == expected_domain)
            },
            ConditionType::ContextCondition => {
                let field_path = condition.parameters.get("field_path")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| AlgebraicError::InvalidCondition(
                        "Context condition requires 'field_path' parameter".to_string()
                    ))?;
                
                let expected_value = condition.parameters.get("value")
                    .ok_or_else(|| AlgebraicError::InvalidCondition(
                        "Context condition requires 'value' parameter".to_string()
                    ))?;

                let actual_value = context.get_value(field_path);
                Ok(actual_value == Some(expected_value))
            },
            ConditionType::EventTypeCondition => {
                let expected_type = condition.parameters.get("event_type")
                    .and_then(|v| v.as_str())
                    .ok_or_else(|| AlgebraicError::InvalidCondition(
                        "Event type condition requires 'event_type' parameter".to_string()
                    ))?;
                Ok(event.type_name() == expected_type)
            },
            ConditionType::CustomCondition => {
                // Custom conditions can be extended by domain implementations
                Ok(true) // Simplified for base implementation
            },
        }
    }
}

/// Domain routing transformation
pub struct DomainRoutingTransformation {
    /// Target domain
    pub target_domain: String,
    /// Routing configuration
    pub config: HashMap<String, serde_json::Value>,
}

#[async_trait]
impl EventTransformation<WorkflowEvent> for DomainRoutingTransformation {
    async fn transform(
        &self,
        mut event: WorkflowEvent,
        _context: &WorkflowContext,
    ) -> Result<WorkflowEvent, TransformationError> {
        // Create new event for target domain
        event.id = Uuid::new_v4();
        event.domain = self.target_domain.clone();
        event.timestamp = chrono::Utc::now();
        event.payload.set_data(
            "routed_from_domain".to_string(),
            serde_json::json!(event.domain.clone())
        );
        event.payload.set_data(
            "routing_transformation".to_string(),
            serde_json::json!("domain_routing")
        );

        Ok(event)
    }
}

/// Context enrichment transformation
pub struct ContextEnrichmentTransformation {
    /// Additional context data
    pub context_data: HashMap<String, serde_json::Value>,
}

#[async_trait]
impl EventTransformation<WorkflowEvent> for ContextEnrichmentTransformation {
    async fn transform(
        &self,
        mut event: WorkflowEvent,
        _context: &WorkflowContext,
    ) -> Result<WorkflowEvent, TransformationError> {
        // Add enrichment data to event context
        for (key, value) in &self.context_data {
            event.context.add_domain_context(key.clone(), value.clone());
        }

        event.payload.set_data(
            "enriched_at".to_string(),
            serde_json::json!(chrono::Utc::now().to_rfc3339())
        );

        Ok(event)
    }
}

/// Algebraic operation errors
#[derive(Debug, thiserror::Error)]
pub enum AlgebraicError {
    #[error("Invalid composition: {0}")]
    InvalidComposition(String),

    #[error("Invalid condition: {0}")]
    InvalidCondition(String),

    #[error("Transformation error: {0}")]
    TransformationError(#[from] TransformationError),

    #[error("Context error: {0}")]
    ContextError(String),
}

/// Event transformation errors
#[derive(Debug, thiserror::Error)]
pub enum TransformationError {
    #[error("Transformation failed: {0}")]
    TransformationFailed(String),

    #[error("Invalid transformation parameters: {0}")]
    InvalidParameters(String),

    #[error("Domain routing error: {0}")]
    DomainRoutingError(String),
}

impl Default for OperationMetrics {
    fn default() -> Self {
        Self {
            duration_us: 0,
            events_processed: 0,
            causations_created: 0,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::algebra::event_algebra::*;
    use crate::primitives::{UniversalWorkflowId, WorkflowInstanceId};

    #[tokio::test]
    async fn test_sequential_composition() {
        let algebra = WorkflowEventAlgebra;
        let correlation_id = Uuid::new_v4();

        let event1 = WorkflowEvent::lifecycle(
            LifecycleEventType::WorkflowCreated,
            "workflow".to_string(),
            correlation_id,
            EventPayload::empty(),
            EventContext::empty(),
        );

        let event2 = WorkflowEvent::lifecycle(
            LifecycleEventType::WorkflowStarted,
            "workflow".to_string(),
            correlation_id,
            EventPayload::empty(),
            EventContext::empty(),
        );

        let workflow_id = UniversalWorkflowId::new("workflow".to_string(), None);
        let instance_id = WorkflowInstanceId::new(workflow_id.clone());
        let context = WorkflowContext::new(workflow_id, instance_id, None);

        let result = algebra.compose_sequential(event1, event2, &context).await;
        assert!(result.is_ok());

        let composed = result.unwrap();
        assert_eq!(composed.events.len(), 2);
        assert_eq!(composed.causations.len(), 1);
        assert_eq!(composed.metadata.operation_type, OperationType::SequentialComposition);
    }

    #[tokio::test]
    async fn test_parallel_composition() {
        let algebra = WorkflowEventAlgebra;
        let correlation_id = Uuid::new_v4();

        let event1 = WorkflowEvent::step(
            StepEventType::StepStarted,
            "workflow".to_string(),
            correlation_id,
            EventPayload::empty(),
            EventContext::empty(),
        );

        let event2 = WorkflowEvent::step(
            StepEventType::StepStarted,
            "workflow".to_string(),
            correlation_id,
            EventPayload::empty(),
            EventContext::empty(),
        );

        let workflow_id = UniversalWorkflowId::new("workflow".to_string(), None);
        let instance_id = WorkflowInstanceId::new(workflow_id.clone());
        let context = WorkflowContext::new(workflow_id, instance_id, None);

        let result = algebra.compose_parallel(event1, event2, &context).await;
        assert!(result.is_ok());

        let composed = result.unwrap();
        assert_eq!(composed.events.len(), 2);
        assert_eq!(composed.causations.len(), 1);
        assert_eq!(composed.metadata.operation_type, OperationType::ParallelComposition);
    }

    #[tokio::test]
    async fn test_conditional_transformation() {
        let algebra = WorkflowEventAlgebra;
        let correlation_id = Uuid::new_v4();

        let event = WorkflowEvent::lifecycle(
            LifecycleEventType::WorkflowCreated,
            "workflow".to_string(),
            correlation_id,
            EventPayload::empty(),
            EventContext::empty(),
        );

        let condition = TransformationCondition {
            name: "domain_check".to_string(),
            condition_type: ConditionType::DomainCondition,
            parameters: vec![("domain".to_string(), serde_json::json!("workflow"))]
                .into_iter().collect(),
        };

        let transformation = Box::new(DomainRoutingTransformation {
            target_domain: "person".to_string(),
            config: HashMap::new(),
        });

        let workflow_id = UniversalWorkflowId::new("workflow".to_string(), None);
        let instance_id = WorkflowInstanceId::new(workflow_id.clone());
        let context = WorkflowContext::new(workflow_id, instance_id, None);

        let result = algebra.transform_conditional(event, condition, transformation, &context).await;
        assert!(result.is_ok());

        let transformed = result.unwrap();
        assert_eq!(transformed.result.domain, "person");
        assert_eq!(transformed.metadata.operation_type, OperationType::ConditionalTransformation);
    }

    #[test]
    fn test_identity_elements() {
        let seq_identity = WorkflowEventAlgebra::sequential_identity();
        let par_identity = WorkflowEventAlgebra::parallel_identity();

        assert!(seq_identity.correlation_id.is_nil());
        assert!(par_identity.correlation_id.is_nil());
    }
}